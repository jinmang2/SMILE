{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from khaiii import KhaiiiApi\n",
    "from konlpy.tag import Okt, Komoran, Kkma, Mecab\n",
    "from chatspace import ChatSpace\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nsmc_data():\n",
    "    # data load\n",
    "    paths = [path.replace('\\\\', '/') for path in glob('./nsmc/raw/*.json')]\n",
    "    res = []\n",
    "    for path in paths:\n",
    "        with open(path, encoding='utf-8') as data_file:\n",
    "            res.extend(json.load(data_file))\n",
    "    # struct dataframe\n",
    "    df = pd.DataFrame(res)\n",
    "    # drop null data & \\n, \\r\n",
    "    df['review'] = df['review'].map(lambda x : re.sub('[\\n\\r]', '', x))\n",
    "    df = df[df['review'].map(lambda x : len(x) != 0)]\n",
    "    df.index = range(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_nsmc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "spacer = ChatSpace(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 137 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%time spacing_reviews = spacer.space(df.review.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = KhaiiiApi()\n",
    "\n",
    "def tokenize(self, text, morphs=False, split=False):\n",
    "    results = self.analyze(text)\n",
    "    results = ' + '.join(list(map(lambda s: str(s).split('\\t')[1], results)))\n",
    "    if morphs:\n",
    "        results = list(map(lambda s: s.split('/')[0], results.split(' + ')))\n",
    "        results = ' + '.join(results)\n",
    "    if split:\n",
    "        results = results.split(' + ')\n",
    "    return results\n",
    "\n",
    "setattr(tokenizer.__class__, 'tokenize', tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_review(text, tokenizer, *args, **kwargs):\n",
    "    letters_only = re.sub('[^0-9ㄱ-ㅎㅏ-ㅣ가-힣.,!?*♡]', ' ', text).strip()\n",
    "    return tokenizer.tokenize(letters_only, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 4.01 ms, total: 2.31 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews = list(map(lambda s: re.sub('[^0-9ㄱ-ㅎㅏ-ㅣ가-힣.,!?*♡]', ' ', s), spacing_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 7s, sys: 2.28 s, total: 10min 9s\n",
      "Wall time: 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_reviews = [tokenizer.tokenize(text, split=True) for text in spacing_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df4a43e24a2432fbbdde8a3a5d96393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=712383.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "_reviews = []\n",
    "\n",
    "for text in tqdm(spacing_reviews):\n",
    "    _reviews.append(okt.morphs(text, norm=True, stem=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Khaiii\n",
    "# with open('tokenized_reviews.pkl', 'wb') as f:\n",
    "#     pickle.dump(_reviews, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('tokenized_reviews.pkl', 'rb') as f:\n",
    "#     _reviews = pickle.load(f)\n",
    "\n",
    "# Open Korean Text\n",
    "with open('tokenized_reviews_okt.pkl', 'wb') as f:\n",
    "    pickle.dump(_reviews, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('tokenized_reviews_okt.pkl', 'rb') as f:\n",
    "    _reviews = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712383"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reviews.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokens = Counter([i for review in _reviews for i in review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "JST = SentimentLDAGibbsSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 10, 'beta': 0.1, 'gamma': 0.1, 'numTopics': 4, 'numSentiments': 8}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JST.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
